# Cantareira's Runtime Environment

_Table of Contents:_
* [Mesos overview](#mesos-overview)
* [Aurora overview](#aurora-overview)
* [Airflow overview](#airflow-overview)
* [Deployment](#deployment)
* [Types of Mesos Slaves](#types-of-mesos-slaves)
* [Ops](#ops)
  * [Checking running instances](#checking-running-instances)
  * [Executor logs](#executor-logs)
  * [Updating Mesos IAM Roles](#updating-mesos-iam-roles)

The runtime relies on [Apache Mesos](mesos.apache.org) for managing the resources, every ec2 instance that we use in the [Nightly Run](https://github.com/nubank/data-infra-docs/blob/master/monitoring_nightly_run.md) register itself as a Mesos Slave and its resources becomes available in the Mesos's pool of resources. For running jobs [Apache Aurora](https://github.com/nubank/aurora-jobs/blob/master/README.md#whats-aurora) is used, which register as a [Mesos Framework](http://mesos.apache.org/documentation/latest/architecture/) and accept Mesos offers.

When creating an Aurora Job, you need to specify the resources that this job is going to use, Aurora manages to accept offers from Mesos and run this process on a slave with enough capacity. More on this [Resource Isolation](http://aurora.apache.org/documentation/latest/features/resource-isolation/) and [Constraints](http://aurora.apache.org/documentation/latest/features/constraints/).

## Mesos overview

TODO: fill me in
 - What are agents
 - What are executors
 - What are frameworks
 - What are drivers

## Aurora overview

  * [Aurora](http://aurora.apache.org/) is a resource manager that schedules and runs jobs across a [Mesos](http://mesos.apache.org/) cluster. All our jobs run inside Docker containers, so each job can execute arbitrary code written in separate languages/frameworks, as long as they are able to run on Linux.
  * The job definitions are written as a `.aurora` files and stored in the [aurora-jobs](https://github.com/nubank/aurora-jobs/tree/master/jobs) repo. `.aurora` files are [Pystachio](https://github.com/wickman/pystachio) templates that generate Python code to define the jobs themselves. A good reference to start understanding how they are structured is [the official tutorial](http://aurora.apache.org/documentation/latest/reference/configuration-tutorial/).
  * A short description of the jobs:
    * `itaipu-*` jobs run Spark driver nodes to run datasets defined in [itaipu](#itaipu-overview). The Spark driver nodes talk directly to Mesos to get more resources, so only the driver node is managed via Aurora.
    * `scale-ec2-*` and `downscale-ec2-*` jobs add more machines to the Mesos cluster to run other jobs. Since AWS charges us per second of running time per instance, we scale up separate pools of machines for each `itaipu` job and Python machine learning model to have better isolation and debugging. The code to scale up and down the instances is in a small Python project we wrote called [scale-cluster](https://github.com/nubank/scale-cluster).
    * `capivara-clj` is a job to run [capivara-clj](#capivara-clj-overview), which loads datasets generated by Itaipu to Redshift.
    * `*-model` are a set of jobs to run Python machine learning models. Most of them are defined in [batch-models-python](https://github.com/nubank/batch-models-python), a project maintained by the data scientists.

## Airflow overview

Airflow is the piece which controls when to execute, what to execute and what's the execution order. All code related to Airflow is a normal python code and is in the [airflow](https://github.com/nubank/aurora-jobs/tree/master/airflow) directory on [aurora-jobs](https://github.com/nubank/aurora-jobs/).

More stuff at [Airflow maintenance](/airflow.md)

## Deployment

Creating a `MesosCluster` is done using the [Deploy](https://github.com/nubank/deploy), follow the guide in the project's README to install it.

1. Start the console using the cantareira environment `./console cantareira`
2. To create/update the cluster just type: `MesosCluster.create!("test")`.
3. To update individual Slaves you can type: `MesosFixed.create!("test")`, `MesosOnDemand.create!("test")`

As most of the things on Nubank, Mesos also runs as a container inside a `CoreOS` instance, the container definition is in the [dockerfiles](https://github.com/nubank/dockerfiles/) project. To change it you need to open a PR, get it merged, a pipeline on GO will build the docker image and then you need to update the mesos version in both [deploy](https://github.com/nubank/deploy/blob/master/lib/recipes/mesos_cluster.rb#L30) and in the [scale-cluster](https://github.com/nubank/scale-cluster/blob/master/src/scale_cluster/ec2.py#L155) projects.

## Types of Mesos Slaves

We have several types of mesos slaves, one for each kind of workload. They can be specified when running a job by defining [Constraints](http://aurora.apache.org/documentation/latest/features/constraints/) in the aurora job file, eg: `constraints={'slave-type': 'mesos-fixed'}`.

* **Fixed Instances** - Created by the `MesosFixed` recipe, those instances doesn't scale up and down when we scale the cluster, that's the instance type that you want to use when your job is not fault tolerant.
* **General On-Demand Instances** - Created by the `MesosOnDemand` recipe, those instances are spin scaling up the `mesos-on-demand` auto-scaling group, every `MesosCluster` has an On Demand autoscaling group.
  * can be scaled up using the following command: `sabesp --verbose --aurora-stack=cantareira-stable jobs create prod scale MODE=on-demand N_NODES=0 SCALE_TIMEOUT=5 --job-version scale_cluster=df8da67`
* **Spot Instances** -  Created by the `MesosMultiAZSpotInstances` recipe, same as the on-demand but spins up spot-instances.
  * can be scaled up using the following command: `sabesp --verbose --aurora-stack=cantareira-stable jobs create prod scale MODE=spot-only N_NODES=0 SCALE_TIMEOUT=5 --job-version scale_cluster=df8da67`
* **Specific On Demand Instances** - Those instances are created using the [scale-cluster](https://github.com/nubank/scale-cluster) `scale-ec2` enstrypoint, this differs from the other slaves by spinning individual ec2 instances (not in auto-scale cluster) so you can specify different attributes for each instance (like: instance type, naming etc.).
  * can be scaled up using the following command: `sabesp --aurora-stack=cantareira-stable jobs create prod downscale-ec2-model SLAVE_TYPE=model NODE_COUNT=1 --job-version="scale_cluster=d749aa4" --filename scale-ec2`

## Ops

### Checking running instances

You can check if the instances are running on the [AWS Console](https://console.aws.amazon.com/ec2/v2/home?region=us-east-1#Instances:tag:Name=cantareira-dev-mesos-on-demand-;sort=instanceId) and check the status of your jobs [here](https://cantareira-dev-mesos-master.nubank.com.br:8080/scheduler/jobs). Now wait, it might take a while.

### Executor logs

Most of the logs relevant to issues are found on [aurora](https://cantareira-stable-mesos-master.nubank.com.br:8080/scheduler/jobs/prod).

In the rare case that you want to see executor logs, navigate to [https://cantareira-stable-mesos-master.nubank.com.br/](https://cantareira-stable-mesos-master.nubank.com.br/)

From here you will need to manually navigate to the direct ip due to some dns issues.
look in the top left, where you will see something like:

```
Leader: ip-10-130-118-157.ec2.internal:5050
```

Navigate to that IP `10.130.118.157:5050`

Find your relevant active task and click `Sandbox` (note that opening this link in a new browser window is unsupported).
In the sandbox you can check the `stderr` and `stdout` logs.

Note that while doing this you will probably want to keep the machine up by disabling downscaling ([see here for instructions](ops_how_to.md#keep-machines-up-after-a-model-fails)).

### Updating Mesos IAM Roles

IAM roles are stored in a separate project [iam-policies](https://github.com/nubank/iam-policies), to update them you need to change the file that corresponds the slave you want to change (or change all of them) files are:
* [Mesos Fixed Role](https://github.com/nubank/iam-policies/blob/master/mesos-fixed.json)
* [Mesos On-Demand Role](https://github.com/nubank/iam-policies/blob/master/mesos-on-demand.json)
* [Mesos Spot Multi Az Role](https://github.com/nubank/iam-policies/blob/master/mesos-spot-multi-az.json)
* [Mesos Master Role](https://github.com/nubank/iam-policies/blob/master/mesos-master.json)

Policies for mesos are inside the Mesos [directory](https://github.com/nubank/iam-policies/blob/master/policies/mesos/).

After you make a change, you need to deploy the changes via nucli:
```
nu iam create roles stable mesos-fixed --env cantareira
```

Done, now the iam-role for **mesos-fixed** in the stack **stable** is updated.
